# Healthcare Document Chat API

An intelligent **FastAPI-based backend service** that processes healthcare documents and enables natural language chat interactions over their content using **RAG (Retrieval-Augmented Generation)**.

---

## Project Overview

This API allows users to upload medical documents such as lab reports, prescriptions, or clinical notes, and then query them conversationally.  
It integrates:

- Document ingestion and text extraction
- Text preprocessing and intelligent chunking
- Vector embeddings for semantic retrieval
- Conversational AI via RAG pipeline
- Medical entity recognition and healthcare-specific responses

---

## Setup Instructions

### 1. **Clone the Repository**

```bash
git clone https://github.com/<your-username>/healthcare-chat-api.git
cd healthcare-chat-api
```

### 2. **Create a Virtual Environment**

```bash
# Create
python -m venv .venv

# Activate (Windows)
.venv\Scripts\activate

# or (Mac/Linux)
source .venv/bin/activate

```

### 3. Install Dependencies

```bash
pip install --upgrade pip
pip install -r requirements.txt

```

### 4. Run the Application

```bash
uvicorn app.main:app --reload
```

Then open your browser at: http://127.0.0.1:8000/docs

---

## **Document Upload and Processing Layer**

This stage establishes the FastAPI backend for secure ingestion and structured processing of healthcare documents. It provides validated uploads, text extraction, and metadata management, the foundation for downstream AI workflows.

### **Core Functionality**

- **File Upload (`/api/v1/documents/upload`)**

  - Accepts **PDF**, **DOCX**, and **TXT** files.
  - Validates MIME type and limits file size to **10 MB**.
  - Stores uploaded files temporarily in `uploads/`.
  - Extracts text using:

    - `PyPDF2` → PDFs
    - `python-docx` → Word
    - UTF-8 read → TXT

  - Handles corrupted files and invalid formats gracefully.
  - Returns metadata via the `DocumentResponse` Pydantic model.

- **Metadata Storage**

  - Maintains in-memory document registry (`documents_db`) for active session tracking.
  - Each record stores file info, extraction length, and status.
  - Future phases will replace this with persistent vector storage.

### **Available Endpoints**

| Method     | Endpoint                          | Description                         |
| :--------- | :-------------------------------- | :---------------------------------- |
| **GET**    | `/api/v1/health`                  | Service health check                |
| **POST**   | `/api/v1/documents/upload`        | Upload and extract document text    |
| **GET**    | `/api/v1/documents/`              | List all uploaded documents         |
| **GET**    | `/api/v1/documents/{document_id}` | Retrieve specific document metadata |
| **DELETE** | `/api/v1/documents/{document_id}` | Remove stored file and metadata     |

### **Error Handling**

| Scenario                 | HTTP Code | Message                 |
| ------------------------ | --------- | ----------------------- |
| Invalid file type        | 415       | Unsupported file type   |
| File too large (> 10 MB) | 413       | File size exceeds limit |
| Extraction failure       | 500       | Text extraction failed  |
| Unknown document ID      | 404       | Document not found      |

### **Logging**

Centralized in `app/utils/logger.py`, recording all upload, extraction, and deletion events:

```
2025-10-20 22:14:33 | INFO | Uploaded lab_report.pdf (pdf)
2025-10-20 22:15:47 | ERROR | Unsupported file type: image.jpeg
```

### **Design Notes**

- Modular router structure for clean scaling (`documents`, `chat`).
- In-memory DB for simplicity during development.
- Strong Pydantic models ensure consistent API documentation.
- Errors surfaced with accurate HTTP codes for clarity.

### **Limitations**

- No persistence beyond runtime.
- Extraction limited to text-based PDFs (no OCR).
- Sync I/O; async and streaming to be added later.

Next, the pipeline will expand to include **text cleaning and semantic chunking** to prepare for embedding generation.

## Disclaimer ❗

This project is for educational and demonstration purposes only.
Responses generated by the model are not medical advice and should not be used for clinical decision-making.
